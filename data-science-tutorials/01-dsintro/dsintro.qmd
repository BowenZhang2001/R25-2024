---
title: "Data Science and R"
author: "Dr. Roch Nianogo, Bowen Zhang, Dr. Hua Zhou"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
jupyter:
    kernelspec:
        name: "ir43"
        language: "R"
        display_name: "R 4.3.2"    
comments:
  hypothesis: true    
---

```{r}
#| code-fold: true
#| output: false

# setup code: install packages
library(tidyverse)
```

## Roadmap

A typical data science project:

<p align="center">

<img src="./data-science.png" width="80%"/>

</p>

### Learning objectives

In the next 1.5 days, we learn

-   the life cycle of a data science project

-   some R ecosystems (tidyverse, tidymodels) for Open Data Science

-   basic machine learning

-   policy evaluation using double machine learning

Dr. Roch Nianogo will lead the second part, from June 25 afternoon to June 26, with in-depth discussions of simulation modeling, causal inference, and linking data science and systems science.

### Course materials

During the course, you can

-   read the static tutorial pages, make comments, and ask questions; or

-   interactively run `qmd` codes in RStudio on [Posit Cloud](https://posit.cloud/spaces/522857/join?access_code=jp20j2u42A7Ygue-OICZ2U4S6IWZCnI5GFp0r_N9) (sign up for a free account); or

-   interactively run `ipynb` codes in Jupyter Notebook on [Binder](https://mybinder.org/v2/gh/NIH-R25-ModelersAndStoryTellers/binder-sandbox.git/main?urlpath=git-pull?repo=https://github.com/NIH-R25-ModelersAndStoryTellers/2024.git) (can be slow)

Adventurous ones can reproduce, improve, and generalize all the examples **on your own computer** by the following steps:

-   install [R](https://cran.r-project.org/), [RStudio](https://www.rstudio.com/products/rstudio/download/), and [Quarto](https://quarto.org/docs/get-started/)

-   git clone the [course repository](https://github.com/NIH-R25-ModelersAndStoryTellers/2024)

-   revise and render the qmd files

### Questions, please

Please feel free to ask questions and make comments. You can

-   use the "raise hand" feature (âœ‹) in Zoom

-   type your questions in the Zoom chat (ðŸ’¬)

-   make comments or ask questions on tutorial pages (need to sign up an account on [hypothes.is](https://web.hypothes.is/))

## Data source

### Current Population Survey (CPS)

::: {style="text-align: center;"}
<img src="https://www.census.gov/etc.clientlibs/census/clientlibs/census-pattern-library/resources/images/USCENSUS_IDENTITY_SOLO_BLACK_1.5in_R_no_padding.svg" alt="Census Bureau" width="240"/>
:::

The [Current Population Survey (CPS)](https://www.census.gov/programs-surveys/cps.html), sponsored jointly by the U.S. Census Bureau and the U.S. Bureau of Labor Statistics (BLS), is the primary source of labor force statistics for the population of the United States.

The CPS is one of the oldest, largest, and most well-recognized surveys in the United States. It is immensely important, providing information on many of the things that define us as individuals and as a society â€“ our work, our earnings, and our education.

In addition to being the primary source of monthly labor force statistics, the CPS is used to collect data for a variety of other studies that keep the nation informed of the economic and social well-being of its people. This is done by adding a set of supplemental questions to the monthly basic CPS questions. Supplemental inquiries vary month to month and cover a wide variety of topics such as child support, volunteerism, health insurance coverage, school enrollment, and **food security**. A listing and brief description of the CPS supplements are available [here](https://www.census.gov/programs-surveys/cps/about/supplemental-surveys.html).

### Food Security Supplement (CPS-FSS)

Take the **CPS Food Security Supplement December 2021 Public-Use Microdata File** as an example. The Food Security Supplement was completed for 30,343 interviewed households with 71,571 person records.

The microdata file includes data in four general categories:

-   Monthly labor force survey data (geographic, demographic, income, employment)
-   Food Security Supplement data (household food expenditures, use of food assistance programs, experiences and behaviors related to food security)
-   Food security status
-   Weighting variables

Food Security Supplement Questionnaire includes the following major sections:

-   Food Spending
-   Minimum Food Spending Needed
-   Food Assistance Program Participation
-   Food Sufficiency and Food Security
-   Ways of Avoiding or Ameliorating Food Deprivation

It is worth noting that beginning in 2015 and continuing through 2021, there were changes from previous years in how the Census Bureau processes some variables. Details can be found in the technical documentation, which can be found [here](https://www.census.gov/data/datasets/time-series/demo/cps/cps-supp_cps-repwgt/cps-food-security.html)

## Introduction to R

### Tidyverse

-   [tidyverse](https://www.tidyverse.org/) is a collection of R packages for data ingestion, wrangling, and visualization.

::: {style="text-align: center;"}
<img src="https://hbctraining.github.io/Intro-to-R/img/tidyverse_website.png" alt="Tidyverse"/>
:::

As it is difficult to change how fundamental base R structures/functions work, the Tidyverse suite of packages create and use data structures, functions and operators to make working with data more intuitive. The two most basic changes are in the use of pipes and tibbles.

-   The lead developer Hadley Wickham won the 2019 *COPSS Presidentsâ€™ Award* (the Nobel Prize of Statistics)

> for influential work in statistical computing, visualization, graphics, and data analysis; for developing and implementing an impressively comprehensive computational infrastructure for data analysis through R software; for making statistical thinking and computing accessible to large audience; and for enhancing an appreciation for the important role of statistics among data scientists.

#### Pipes

Stringing together commands in R can be quite daunting. Also, trying to understand code that has many nested functions can be confusing.

To make R code more human readable, the Tidyverse tools use the pipe, `%>%`, which was acquired from the **magrittr** package and comes installed automatically with Tidyverse. The pipe allows the output of a previous command to be used as input to another command instead of using nested functions.

```{r}
#| eval: true

# A single command
sqrt(83)
```

```{r}
# Base R method of running more than one command
round(sqrt(83), digit = 2)
```

```{r}
# Running more than one command with piping
sqrt(83) %>% round(digit = 2)
```

The pipe represents a much easier way of writing and deciphering R code, and we will be taking advantage of it for all future activities.

::: callout-tip
R 4.1.0 introduced a native pipe operator `|>`, which is mostly compatible with the pipe `%>%` offered by the tidyverse package magrittr. For some subtle differences, see this [post](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) by Hadley Wickham.
:::

```{r}
#| eval: true

# R base pipe
sqrt(83) |> round(digit = 2)
```

#### Tibbles

A core component of the tidyverse is the tibble. Tibbles are a modern rework of the standard data.frame, with some internal improvements to make code more reliable. They are data frames, but do not follow all of the same rules. For example, tibbles can have column names that are not normally allowed, such as numbers/symbols.

The main differences between tibbles and data.frames relate to printing and subsetting.

-   `iris` is a data frame available in base R

::: {style="text-align: center;"}
<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZK9_HrpP_lhSzTq9xVJUQw.png" alt="iris" width="500"/>
:::

```{r}
#| eval: true

# By default, R displays ALL rows of a regular data frame!
iris
```

-   Convert a regular data frame to tibble, which by default only displays the first 10 rows of data.

```{r}
#| eval: true

# Convert iris to a tibble
iris_tb <- as_tibble(iris)
iris_tb
```

```{r}
#| eval: true

# If subsetting a single column from a data.frame, R will output a vector
iris[, "Sepal.Length"]
```

```{r}
#| eval: true

# If subsetting a single column from a tibble, R will output a tibble
iris_tb[, "Sepal.Length"]
```

Also note that if you use piping to subset a tibble, then the notation is slightly different, requiring a placeholder `.` prior to the `[ ]` or `$`.

```{r}
#| eval: false

# Return a vector
iris_tb$Sepal.Length
iris_tb[["Sepal.Length"]]
iris_tb[[1]]

# Return a tibble
iris_tb[, "Sepal.Length"]
iris_tb[, 1]

# Use piping
iris_tb %>% .$Sepal.Length
iris_tb %>% .[, "Sepal.Length"]
```

#### dplyr

The most useful tool in the tidyverse is dplyr. Itâ€™s a Swiss-army knife for data wrangling. dplyr has many handy functions that we recommend incorporating into your analysis.

-   Operations on rows:
    -   `arrange()` changes the ordering of the rows.
    -   `filter()` picks cases based on their values.
    -   `distinct()` removes duplicate entries.
    -   `slice_*()` selects rows by position.
-   Operations on columns:
    -   `select()` extracts columns and returns a tibble.
    -   `mutate()` adds new variables that are functions of existing variables.
    -   `rename()` easily changes the name of a column(s).
    -   `pull()` extracts a single column as a vector.
-   Grouped operations:
    -   `group_by()` aggregates data by one or more variables.\
    -   `summarise()` reduces multiple values down to a single summary.
-   `_join()` functions that merge two data frames together, including `inner_join()`, `left_join()`, `right_join()`, and `full_join()`.

The [Posit dplyr cheatsheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf) is extremely intuitive and helpful.

Some examples of using dplyr functions.

-   Filter observations with `Sepal.Length` greater than 5.0, arrange the data by `Sepal.Length` in descending, and create a new column `Sepal.Length_2` that is the square of `Sepal.Length`.

```{r}
#| eval: true

iris_tb |>
  filter(Sepal.Length > 5.0) |>
  arrange(desc(Sepal.Length)) |>
  mutate(Sepal.Length_2 = Sepal.Length^2) |>
  print()
```

-   Select columns `Species`, and find the distinct values of `Species`

```{r}
#| eval: true

iris_tb |>
  select(Species) |>
  distinct()
```

-   Count the number of rows in each species

```{r}
#| eval: true

iris_tb |>
  group_by(Species) |> 
  summarize(n = n())
```

```{r}
# Shortcut for group_by() |> summarize(n = n())
iris_tb |>
  count(Species)
```

-   Calculate the mean of `Sepal.Length` for each `Species`

```{r}
#| eval: true

iris_tb |>
  group_by(Species) |>
  summarize(mean_Sepal_Length = mean(Sepal.Length))
```

-   Find the observation with the maximum `Sepal.Length` for each `Species`

```{r}
#| eval: true

iris_tb |>
  group_by(Species) |>
  slice_max(Sepal.Length)
```

#### Combine variables (columns)

-   Demo tables

```{r}
#| eval: true

(x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  3, "x3"
))
```

```{r}
#| eval: true

(y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  4, "y3"
))
```

-   An **inner join** matches pairs of observations whenever their keys are equal:

<p align="center">

<img src="./join-inner.png" height="150"/>

</p>

```{r}
#| eval: true

inner_join(x, y, by = "key")
```

-   An **outer join** keeps observations that appear in at least one of the tables.

-   Three types of outer joins: **left join**, **right join**, and **full join**.

<p align="center">

<img src="./join-outer.png" width="50%"/>

</p>

-   A **left join** keeps all observations in `x`.

```{r}
#| eval: true

left_join(x, y, by = "key")
```

-   A **right join** keeps all observations in `y`.

```{r}
#| eval: true

right_join(x, y, by = "key")
```

-   A **full join** keeps all observations in `x` and `y`.

```{r}
#| eval: true

full_join(x, y, by = "key")
```

-   One table has duplicate keys.

<p align="center">

<img src="./join-one-to-many.png" height="200"/>

</p>

```{r}
#| eval: true

x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  1, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2"
)
left_join(x, y, by = "key")
```

-   Both tables have duplicate keys. You get all possible combinations, the Cartesian product:

<p align="center">

<img src="./join-many-to-many.png" height="250"/>

</p>

```{r}
#| eval: true

x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  3, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  2, "y3",
  3, "y4"
)

left_join(x, y, by = "key")
```

#### Combine cases (rows)

-   `semi_join(x, y)` keeps the rows in `x` that have a match in `y`.

<p align="center">

<img src="./join-semi.png" height="200"/>

</p>

```{r}
#| eval: true

x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  3, "x3"
)

y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  4, "y3"
)

semi_join(x, y, by = "key")
```

-   `anti_join(x, y)` keeps the rows that donâ€™t have a match.

<p align="center">

<img src="./join-anti.png" height="200"/>

</p>

```{r}
#| eval: true

anti_join(x, y, by = "key")
```
